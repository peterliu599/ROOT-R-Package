% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ROOT.R
\name{ROOT}
\alias{ROOT}
\title{Ensemble of weighted trees for general optimization and Rashomon selection}
\usage{
ROOT(
  data,
  global_objective_fn = NULL,
  generalizability_path = FALSE,
  leaf_proba = 0.25,
  seed = NULL,
  num_trees = 10,
  vote_threshold = 2/3,
  explore_proba = 0.05,
  feature_est = "Ridge",
  feature_est_args = list(),
  top_k_trees = FALSE,
  k = 10,
  cutoff = "baseline",
  verbose = FALSE
)
}
\arguments{
\item{data}{A data.frame containing the dataset.

In \emph{general optimization} mode (\code{generalizability_path = FALSE}), \code{data} can be
any set of covariates and auxiliary columns. The user supplies a
\code{global_objective_fn} that takes a data frame with a column \code{w}
and returns a scalar loss.

In \emph{generalizability_path} mode (\code{generalizability_path = TRUE}), \code{data} must contain
columns \code{"Y"} (outcome), \code{"Tr"} (treatment indicator, 0/1),
and \code{"S"} (sample indicator, 1 = trial, 0 = target). ROOT internally
constructs transportability scores and, if no custom objective is given,
uses a default variance-based loss.}

\item{global_objective_fn}{function with signature \verb{function(D) -> numeric}
scoring the entire state and minimized by ROOT. If NULL, a default
variance-based objective is used (see \code{objective_default()}).}

\item{generalizability_path}{logical(1). If TRUE, use the built-in transportability
objective based on (Y, Tr, S). If FALSE, treat \code{data} as arbitrary and rely
on \code{global_objective_fn}. Default FALSE.}

\item{leaf_proba}{numeric(1) tuning parameter that increases the chance
a node stops splitting by selecting a synthetic \code{"leaf"} feature.
Internally, the probability of choosing \code{"leaf"} is
\code{leaf_proba / (1 + leaf_proba)} (assuming the
covariate probabilities sum to 1). Default \code{0.25}.}

\item{seed}{optional numeric(1) seed for reproducibility.}

\item{num_trees}{integer(1) number of trees to grow. Default 10.}

\item{vote_threshold}{numeric(1) in (0.5, 1] giving the majority vote
threshold for final \code{w = 1}. Default 2/3.}

\item{explore_proba}{numeric(1) giving the exploration probability at leaves.
Default 0.05.}

\item{feature_est}{either a character(1) in c("Ridge", "GBM") or a
function(X, y, ...) returning a named nonnegative numeric vector of
importances with names matching columns of X. Used only to bias which
covariates are chosen for splitting. If it fails, ROOT falls back to
uniform feature sampling with a warning.}

\item{feature_est_args}{list of additional arguments passed to a user
supplied \code{feature_est} function.}

\item{top_k_trees}{logical(1). If TRUE, select top \code{k} trees by objective;
otherwise use \code{cutoff}. Default FALSE.}

\item{k}{integer(1) giving the number of top trees when
\code{top_k_trees = TRUE}. Default 10.}

\item{cutoff}{numeric(1) or \code{"baseline"}. Used as the Rashomon cutoff when
\code{top_k_trees = FALSE}. \code{"baseline"} uses the objective at w â‰¡ 1.}

\item{verbose}{logical(1). If TRUE, prints unweighted and (when available)
weighted estimates and their standard errors in generalizability_path mode.}
}
\value{
An object of class "ROOT" (a list) with elements:
\itemize{
\item D_rash: data frame with Rashomon-set votes and w_opt.
\item D_forest: data frame with forest-level working columns.
\item w_forest: list of per-tree results from split_node().
\item rashomon_set: indices of selected trees.
\item global_objective_fn: the objective function used.
\item f: summary classifier (e.g., rpart tree) or NULL.
\item testing_data: data frame aligned to rows used to compute scores.
\item estimate: (only if generalizability_path = TRUE) list with unweighted and
weighted estimands, SEs, and a note about the SE.
\item generalizability_path: logical flag.
}
}
\description{
Builds multiple weighted trees, then identifies a "Rashomon set" of
top-performing trees and aggregates their weight assignments by majority vote.
}
\details{
The function is framed as a general functional optimization routine:
given data \eqn{D_n} and a loss \eqn{L(w, D_n)}, ROOT searches over
interpretable tree-based weight functions \eqn{w(d)} in \code{\{0,1\}}.
}
\examples{
\dontrun{
ROOT.output = ROOT(diabetes_data,generalizability_path = TRUE, seed = 123)
}
}
